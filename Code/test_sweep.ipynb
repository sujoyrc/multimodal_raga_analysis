{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac64bcc-a8ec-4afa-89b7-e2f6b564c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "from util_functions import *\n",
    "from objects import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4587f3b0-9db9-457e-9fdb-4dc32501a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_filename': '../Seqs/Seqs_Jin-Normalized-all/easy-1/train_easy-AG.npz', 'test_filename': '../Seqs/Seqs_Jin-Normalized-all/easy-1/test_easy-AG.npz', 'data_artifact': 'easy_1_AG', 'epochs': 10, 'batch_size': 32, 'optimizer': {'type': 'Adadelta', 'learning_rate': 0.01}, 'layers': {'1': {'conv_1': {'filter': 32, 'kernel_size': 5, 'activation': 'linear', 'strides': 1, 'kernel_regularizer': {'l2': {}}}, 'pool_1': {'type': 'Max', 'pool_size': 4, 'strides': 4}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, '2': {'conv_1': {'filter': 16, 'kernel_size': 5, 'activation': 'linear', 'strides': 1, 'kernel_regularizer': {'l2': {}}}, 'pool_1': {'type': 'Max', 'pool_size': 4, 'strides': 4}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, '3': {'conv_1': {'filter': 8, 'kernel_size': 5, 'activation': 'linear', 'strides': 1, 'kernel_regularizer': {'l2': {}}}, 'pool_1': {'type': 'Max', 'pool_size': 4, 'strides': 4}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, '4': {'flatten_1': {}}, '5': {'dense_1': {'units': 250, 'activation': 'linear', 'kernel_regularizer': {'l2': {}}}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, 'output': {'kernel_regularizer': {'l2': {}}}}, 'tags': ['test', 'wandb'], 'project_name': 'Test-wandb', 'run_name': 'test_run', 'model_filename': '../Models/Test-wandb/sweep_model_0.hdf5', 'early_stopping': False}\n"
     ]
    }
   ],
   "source": [
    "with open('../Models/Test-wandb/params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "params['project_name'] = 'Test-wandb'\n",
    "params['run_name'] = 'test_run'\n",
    "params['model_filename'] = '../Models/Test-wandb/sweep_model_0.hdf5'\n",
    "params['early_stopping'] = False\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecce230-d8a3-4760-ab02-4d7369b6b276",
   "metadata": {},
   "source": [
    "### Define and initialise sweep config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d9ae06-7880-4570-86ca-024c79933427",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_loss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"layers.5.dense_1.units\": {\n",
    "                      \"distribution\": \"uniform\",\n",
    "                      \"min\": 10,\n",
    "                      \"max\": 500\n",
    "                    }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40777e99-d683-49cb-8495-a4805ee5fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: omxunhgb\n",
      "Sweep URL: https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=params['project_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534251db-a76a-48fb-a7f9-85b92961125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnnithya\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/snnithya/Test-wandb/runs/1bst7nkr\" target=\"_blank\">light-sponge-148</a></strong> to <a href=\"https://wandb.ai/snnithya/Test-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_filename': '../Seqs/Seqs_Jin-Normalized-all/easy-1/train_easy-AG.npz', 'test_filename': '../Seqs/Seqs_Jin-Normalized-all/easy-1/test_easy-AG.npz', 'data_artifact': 'easy_1_AG', 'epochs': 10, 'batch_size': 32, 'optimizer': {'type': 'Adadelta', 'learning_rate': 0.01}, 'layers': {'1': {'conv_1': {'filter': 32, 'kernel_size': 5, 'activation': 'linear', 'strides': 1, 'kernel_regularizer': {'l2': {}}}, 'pool_1': {'type': 'Max', 'pool_size': 4, 'strides': 4}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, '2': {'conv_1': {'filter': 16, 'kernel_size': 5, 'activation': 'linear', 'strides': 1, 'kernel_regularizer': {'l2': {}}}, 'pool_1': {'type': 'Max', 'pool_size': 4, 'strides': 4}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, '3': {'conv_1': {'filter': 8, 'kernel_size': 5, 'activation': 'linear', 'strides': 1, 'kernel_regularizer': {'l2': {}}}, 'pool_1': {'type': 'Max', 'pool_size': 4, 'strides': 4}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, '4': {'flatten_1': {}}, '5': {'dense_1': {'units': 250, 'activation': 'linear', 'kernel_regularizer': {'l2': {}}}, 'bn_1': {}, 'act_1': {'activation': 'relu'}}, 'output': {'kernel_regularizer': {'l2': {}}}}, 'tags': ['test', 'wandb'], 'project_name': 'Test-wandb', 'run_name': 'test_run', 'model_filename': '../Models/Test-wandb/sweep_model_0.hdf5', 'early_stopping': False}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47396... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">light-sponge-148</strong>: <a href=\"https://wandb.ai/snnithya/Test-wandb/runs/1bst7nkr\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/runs/1bst7nkr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211116_212517-1bst7nkr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(config=params) as run:\n",
    "    config = wandb.config\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242c44c1-e9b0-416a-9a70-ba939d43c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train(config=None):\n",
    "    modelObj = ModelInstance(params, 1200, 9)\n",
    "    modelObj.log_train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0198c799-c0cc-4d87-a08e-a81b7e7bde71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 83dlvcjr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers.5.dense_1.units: 280.6450560509616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/snnithya/Test-wandb/runs/83dlvcjr\" target=\"_blank\">test_run</a></strong> to <a href=\"https://wandb.ai/snnithya/Test-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact easy_1_AG:latest, 60.30MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1200, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1196, 32)          192       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1196, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1196, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 295, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 295, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 69, 8)             648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 69, 8)             32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 69, 8)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 280)               38360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 280)               1120      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 2529      \n",
      "=================================================================\n",
      "Total params: 45,649\n",
      "Trainable params: 44,977\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 12s 57ms/step - loss: 4.9165 - accuracy: 0.1119 - val_loss: 4.7182 - val_accuracy: 0.1080\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 4.8190 - accuracy: 0.1229 - val_loss: 4.7100 - val_accuracy: 0.1080\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 4.7192 - accuracy: 0.1277 - val_loss: 4.6220 - val_accuracy: 0.1121\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 4.6942 - accuracy: 0.1286 - val_loss: 4.5812 - val_accuracy: 0.1337\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 4.6359 - accuracy: 0.1317 - val_loss: 4.5612 - val_accuracy: 0.1389\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 4.5806 - accuracy: 0.1463 - val_loss: 4.5405 - val_accuracy: 0.1420\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 4.5433 - accuracy: 0.1460 - val_loss: 4.5203 - val_accuracy: 0.1461\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 4.5289 - accuracy: 0.1425 - val_loss: 4.4988 - val_accuracy: 0.1451\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 4.4965 - accuracy: 0.1547 - val_loss: 4.4811 - val_accuracy: 0.1420\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 4.4772 - accuracy: 0.1498 - val_loss: 4.4634 - val_accuracy: 0.1461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47462... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▄▄▅█▇██</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▆▇▇██▇█</td></tr><tr><td>val_loss</td><td>██▅▄▄▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.15134</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>4.46339</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>4.4762</td></tr><tr><td>val_accuracy</td><td>0.14609</td></tr><tr><td>val_loss</td><td>4.46339</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test_run</strong>: <a href=\"https://wandb.ai/snnithya/Test-wandb/runs/83dlvcjr\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/runs/83dlvcjr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211116_212532-83dlvcjr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p1xkaaxz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers.5.dense_1.units: 177.5549770779245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/snnithya/Test-wandb/runs/p1xkaaxz\" target=\"_blank\">test_run</a></strong> to <a href=\"https://wandb.ai/snnithya/Test-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact easy_1_AG:latest, 60.30MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1200, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1196, 32)          192       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1196, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1196, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 295, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 295, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 69, 8)             648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 69, 8)             32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 69, 8)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 177)               24249     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 177)               708       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 177)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1602      \n",
      "=================================================================\n",
      "Total params: 30,199\n",
      "Trainable params: 29,733\n",
      "Non-trainable params: 466\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 13s 61ms/step - loss: 4.7765 - accuracy: 0.1122 - val_loss: 4.4510 - val_accuracy: 0.1132\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 4.6597 - accuracy: 0.1129 - val_loss: 4.4600 - val_accuracy: 0.1142\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 4.5858 - accuracy: 0.1148 - val_loss: 4.4269 - val_accuracy: 0.1019\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 4.5311 - accuracy: 0.1041 - val_loss: 4.4036 - val_accuracy: 0.1091\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 6s 37ms/step - loss: 4.4568 - accuracy: 0.1241 - val_loss: 4.3899 - val_accuracy: 0.1204\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 8s 46ms/step - loss: 4.4171 - accuracy: 0.1170 - val_loss: 4.3600 - val_accuracy: 0.1265\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 4.3837 - accuracy: 0.1318 - val_loss: 4.3304 - val_accuracy: 0.1276\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 4.3347 - accuracy: 0.1244 - val_loss: 4.3025 - val_accuracy: 0.1420\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 4.3041 - accuracy: 0.1350 - val_loss: 4.2784 - val_accuracy: 0.1492\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 4.2732 - accuracy: 0.1425 - val_loss: 4.2548 - val_accuracy: 0.1461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47653... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▁▂▄▄▅▆▇█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▇▅▄▄▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▃▃▁▂▄▅▅▇██</td></tr><tr><td>val_loss</td><td>██▇▆▆▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.14132</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>4.25479</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>4.26852</td></tr><tr><td>val_accuracy</td><td>0.14609</td></tr><tr><td>val_loss</td><td>4.25479</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test_run</strong>: <a href=\"https://wandb.ai/snnithya/Test-wandb/runs/p1xkaaxz\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/runs/p1xkaaxz</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211116_212714-p1xkaaxz/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l3mp56rx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers.5.dense_1.units: 278.60968118443174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/snnithya/Test-wandb/runs/l3mp56rx\" target=\"_blank\">test_run</a></strong> to <a href=\"https://wandb.ai/snnithya/Test-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact easy_1_AG:latest, 60.30MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1200, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1196, 32)          192       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1196, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1196, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 295, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 295, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 69, 8)             648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 69, 8)             32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 69, 8)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 278)               38086     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 278)               1112      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 278)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 2511      \n",
      "=================================================================\n",
      "Total params: 45,349\n",
      "Trainable params: 44,681\n",
      "Non-trainable params: 668\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 9s 43ms/step - loss: 5.1178 - accuracy: 0.0820 - val_loss: 4.6994 - val_accuracy: 0.1111\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 7s 37ms/step - loss: 4.9389 - accuracy: 0.0947 - val_loss: 4.6923 - val_accuracy: 0.0936\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 4.8397 - accuracy: 0.1135 - val_loss: 4.6345 - val_accuracy: 0.0967\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 4.7546 - accuracy: 0.1150 - val_loss: 4.6247 - val_accuracy: 0.1132\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 4.6930 - accuracy: 0.1315 - val_loss: 4.6075 - val_accuracy: 0.1245\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 4.6626 - accuracy: 0.1277 - val_loss: 4.5808 - val_accuracy: 0.1214\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 4.6072 - accuracy: 0.1322 - val_loss: 4.5515 - val_accuracy: 0.1255\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 4.5686 - accuracy: 0.1347 - val_loss: 4.5266 - val_accuracy: 0.1337\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 4.5472 - accuracy: 0.1403 - val_loss: 4.5021 - val_accuracy: 0.1368\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 4.5090 - accuracy: 0.1506 - val_loss: 4.4794 - val_accuracy: 0.1430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47813... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▅▅▅▆▇▇█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▃▁▁▄▅▅▆▇▇█</td></tr><tr><td>val_loss</td><td>██▆▆▅▄▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.14597</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>4.4794</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>4.50929</td></tr><tr><td>val_accuracy</td><td>0.143</td></tr><tr><td>val_loss</td><td>4.4794</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test_run</strong>: <a href=\"https://wandb.ai/snnithya/Test-wandb/runs/l3mp56rx\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/runs/l3mp56rx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211116_212857-l3mp56rx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p8r0kw0e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers.5.dense_1.units: 42.24884984587506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/snnithya/Test-wandb/runs/p8r0kw0e\" target=\"_blank\">test_run</a></strong> to <a href=\"https://wandb.ai/snnithya/Test-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact easy_1_AG:latest, 60.30MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1200, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1196, 32)          192       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1196, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1196, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 295, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 295, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 69, 8)             648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 69, 8)             32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 69, 8)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 42)                5754      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42)                168       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 387       \n",
      "=================================================================\n",
      "Total params: 9,949\n",
      "Trainable params: 9,753\n",
      "Non-trainable params: 196\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 9s 47ms/step - loss: 3.6326 - accuracy: 0.1146 - val_loss: 3.3848 - val_accuracy: 0.1204\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 3.5902 - accuracy: 0.1095 - val_loss: 3.4073 - val_accuracy: 0.1091\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 3.5799 - accuracy: 0.1152 - val_loss: 3.4345 - val_accuracy: 0.1193\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 3.5570 - accuracy: 0.1185 - val_loss: 3.4659 - val_accuracy: 0.1049\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 3.5257 - accuracy: 0.1143 - val_loss: 3.4806 - val_accuracy: 0.1029\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 3.5109 - accuracy: 0.1242 - val_loss: 3.4743 - val_accuracy: 0.1029\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 3.4789 - accuracy: 0.1297 - val_loss: 3.4633 - val_accuracy: 0.1091\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 3.4747 - accuracy: 0.1212 - val_loss: 3.4491 - val_accuracy: 0.1091\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 3.4674 - accuracy: 0.1172 - val_loss: 3.4395 - val_accuracy: 0.1111\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 3.4222 - accuracy: 0.1264 - val_loss: 3.4287 - val_accuracy: 0.1101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47970... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▃▃▄▇▆▇▇█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▇▆▅▄▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>█▃█▂▁▁▃▃▄▄</td></tr><tr><td>val_loss</td><td>▁▃▅▇██▇▆▅▄</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.12773</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>3.38484</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>3.43212</td></tr><tr><td>val_accuracy</td><td>0.11008</td></tr><tr><td>val_loss</td><td>3.42871</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test_run</strong>: <a href=\"https://wandb.ai/snnithya/Test-wandb/runs/p8r0kw0e\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/runs/p8r0kw0e</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211116_213033-p8r0kw0e/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m7xlrxi3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers.5.dense_1.units: 11.074157466363218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/snnithya/Test-wandb/runs/m7xlrxi3\" target=\"_blank\">test_run</a></strong> to <a href=\"https://wandb.ai/snnithya/Test-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/sweeps/omxunhgb</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact easy_1_AG:latest, 60.30MB. 2 files... Done. 0:0:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1200, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1196, 32)          192       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1196, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1196, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 16)           2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 295, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 295, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 69, 8)             648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 69, 8)             32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 69, 8)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                1507      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11)                44        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 108       \n",
      "=================================================================\n",
      "Total params: 5,299\n",
      "Trainable params: 5,165\n",
      "Non-trainable params: 134\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 11s 55ms/step - loss: 3.0314 - accuracy: 0.1125 - val_loss: 2.8648 - val_accuracy: 0.1101\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 3.0166 - accuracy: 0.1163 - val_loss: 2.8970 - val_accuracy: 0.0926\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 3.0169 - accuracy: 0.1185 - val_loss: 2.9097 - val_accuracy: 0.1317\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 3.0061 - accuracy: 0.1319 - val_loss: 2.9028 - val_accuracy: 0.1574\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 2.9783 - accuracy: 0.1260 - val_loss: 2.9065 - val_accuracy: 0.1656\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 2.9685 - accuracy: 0.1350 - val_loss: 2.9021 - val_accuracy: 0.1646\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 8s 45ms/step - loss: 2.9600 - accuracy: 0.1359 - val_loss: 2.8972 - val_accuracy: 0.1595\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 2.9595 - accuracy: 0.1357 - val_loss: 2.8896 - val_accuracy: 0.1543\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 2.9560 - accuracy: 0.1379 - val_loss: 2.8865 - val_accuracy: 0.1543\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 2.9423 - accuracy: 0.1298 - val_loss: 2.8807 - val_accuracy: 0.1533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 48257... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▅▅▆▆▇█▆</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▇▆▆▄▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▃▁▅▇██▇▇▇▇</td></tr><tr><td>val_loss</td><td>▁▆█▇▇▇▆▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.12952</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>2.86476</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>2.93824</td></tr><tr><td>val_accuracy</td><td>0.15329</td></tr><tr><td>val_loss</td><td>2.88068</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test_run</strong>: <a href=\"https://wandb.ai/snnithya/Test-wandb/runs/m7xlrxi3\" target=\"_blank\">https://wandb.ai/snnithya/Test-wandb/runs/m7xlrxi3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211116_213220-m7xlrxi3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021812eb-dec1-498b-964c-6df1a18f2d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
