# Basic functionalities

The scripts below can be run in the order listed, the output of one script might be used as input for the next script. 

For example, to run the early fusion (6 channel experiment on AG easy split from the beginning) follow:
1. Dataset creation (create a 6 channel dataset for AG easy_1, i.e. use the Audio_600 and Video_600 folders from Teams as input)
2. Loading the dataset to wandb (using the example json at Example-JSONs/easy_1-AG-6channels)
3. Training + evaluation (using the example json at Example-JSONs/params.json)
4. Sweep - optional (using Example-JSONs/sweep_config.json)

Evaluation can be done by loading another dataset (CC or SCh) onto wandb and evaluating the trained model from the previous steps on that new dataset.

Ensemble predictions can be done after hyperparameter tuning is done (from the sweep set) and the optimal hyperparameters are trained on all 3 data splts. 

*Note: I have changed the default project name on wandb to be 'Gesture Analysis - Temp' so that no changes are made to the current project while we are trying to experiment with the code. Please feel free to change the default project name on lines 143, 204 of the 'util_functions.py' file whenever necessary.

## Dataset creation
This is handled by 'DATASET_CREATION_DRIVER_SCRIPT.py'. Files required for this script include:
1. summaryFile - this is a csv file that explicitly states the file name, raga, start time, end time and unique id of all the sequences from a dataset.
Note about this file: there are 3 versions of this file that I had used due to the different sample rates (all uploaded on Teams: Gesture Analysis > Data for Code > Summary files): 'summary.csv' which was used for all unimodal audio experiments (start/end times are multiples of 0.01s), 'mod-summary.csv' which was used for all unimodal video experiments (start times are multiples of 0.04s) and 'summary_precise.csv' which was used for all multimodal experiments (C and D) (start times are multiples of 0.02s). Experiment E used outputs from unimodal predictions. 
**This file can be generated by the create_summary() function in data-extraction-pipeline.py.**
2. class_index_file - a csv that maps the raga's class number (used during training) to the raga label (also uploaded in teams (Gesture Analysis > Data for Code > raga_mapping.csv), this file is created while using the create_summary() function is point number 1.)
3. If audio data is being generated, location of the folder with pitch files needs to be given. These pitch files can be generated with the script **extract_ss_pitch.py**. (The pitch files are on teams in the Data for Code > audio data). Note: this script will not generate the mask column (as seen in the files on Teams), this can be generated by a simple if statement on the 'pitch' column - 'if row['pitch'] != -3000 1 else 0'. To resample the pitch data use the **resample_data.py** script.
3. If video data is being generated, location of the folder with *processed* openpose csv files needs to be given. (The files are on teams in the Data for Code > Video_300, Video_600). If you wish to process the original open pose files you will have to use the **replace_nan(), filter_data(), normalize_data() functions from new_data_extraction_video_pipeline.py in that order**. To resample the openpose data use the **resample_data.py** script.
4. splitFolder - a folder with files indicating different train-test splits. Each file is named according to the split and contains a list of files (each file on a new line) that occur in the test set. (All splits described in the CJ paper have been uploaded on teams in a folder named splits)

A sample call for this script: `python DATASET_CREATION_DRIVER_SCRIPT.py BOTH <summaryFile> <class_index_file> <splitFolder> -ai <audio_folder> -vi <video folder> -o <output folder>`

## Loading a dataset to wandb
LOG_AND_LOAD_DATA.py takes care of this. It loads npz files generated by the data creation script (listed above) and uploads a separate file for train and test data on wandb. This script requires a config json file indicating the wandb artifact name and location of the npz files on your local system. A sample file is present at **Example-JSONs/easy_1-AG-audio-6channels.json**

## Training + Evaluation
This is handled by the 'MODEL_TRAINING_DRIVER_SCRIPT'. This script creates a model based on a json file (that defines it's architecture) and logs it automatically to wandb. There are few variables in the script file that can be changed on lines 15-17. They include:
1. no_classes - these indicate the number of output classes (ragas). This value has been fixed at 9 through the course of this project.
2. LOG_TRAIN_METADATA - if true, this logs the predictions every 50 epochs. It also logs the weights and gradients during training from each epoch. If you wish to change how many things are getting logged, you will have to alter the parameters in the WandbCallback() on line 635 of the **objects.py** file.
3. LOG_EVALUATION - if true, it will log the predictions from the trained model as a wandb table.  

An example json file describing model architecture is available at **Example-JSONs/params.json**.

A sample call for this script: `python MODEL_TRAINING_DRIVER_SCRIPT.py <config json> | <OPTIONAL> -data <data-artifact-name>`
- *Note: the data artifact name doesn't include the version number, by default the latest version of the data artifact name is downloaded from wandb.*
- to see the other arguements, use `python MODEL_TRAINING_DRIVER_SCRIPT.py -h`
- Note that this script automatically logs a confusion matrix and evaluation metrics like validation accuracy, loss and train accuracy and loss evaluated on the trained model.

## Running a sweep (hyperparameter tuning)
Hyperparameter tuning is done using the wandb sweep function. This is taken care of by 'SWEEP.py'. This script requires and model config file (similar to the one needed for model training) and a sweep config file (this lists the hyperparameters and the range of values that they can take during training)

A sample json file is available at **Example-JSONs/sweep.json**.

A sample call for this script: `python SWEEP.py <model config json> -sf <sweep config json>`

## Evaluation
This script does evaluation of a trained model if required (this is done by default in the training script). This is handled by the 'LOG_EVALUATE.py' script.

A sample call for this script: `python LOG_EVALUATE.py <trained model name with version on wandb> <data artifact name without version number on wandb>`
- *Note: the data artifact name doesn't include the version number, by default the latest version of the data artifact name is downloaded from wandb.*
- to see the other arguements, use `python LOG_EVALUATE.py -h`

## Ensemble model prediction generation
In our paper, we present the metrics from an ensemble of 3 models (each hyperparameter tuned on one of the 3 singers). In order to generate the test accuracy and predictions from the ensemble model, 'ensemble_preds.py' is used. This script includes, the trained_model artifact names, data artifact name(s) defined between lines 10-16. Please add the correct values here and run the script.

# Index of all files in this repo

1. Analyse Predictions.ipynb - Helps analyse audio and video predictions together
2. analyse_video_data.ipynb - Plots the video data as curve  
3. Breath-pauses.ipynb - ipynb to study breath phrases and breath pauses in a given song
4. calculate_mid_frame_summaries.py - calculates the mid frame number for each sequence (written into summary-mod). Used to generate prediction videos.
5. check_predictions.py - script used to check if the weights are actually frozen when using latent fusion (ensemble model)
6. cnn-keras.ipynb - template notebook to run a cnn model
7. compare-data.ipynb - ipynb to compare two datasets
8. create_data_for model.py - creates train and test data depending on the function chosen. The subsequences extracted are chosen based on the summary file created with extract_seqs script.
9. data-extraction-utils.py - utility functions for data extraction pipeline for multichannels
10. data_for_hemantha.py - chose relavant from the Data folder to share
11. data_gen_solo-nithya.py - edited version of Jin's code to create the data for each subsequence. (used before music_raga_gendata_nithy.py).
12. data-extraction-pipeline.py - script to extract data from multichannels and create train and test sets
13. deepsrgm.yml - conda env used on local system and lab PC (without GPU)
14. durations.ipynb - ipynb to study the durations of songs in a dataset
15. ensemble_preds.py - creates a table of ensemble predictions and logs it on wandb
16. evaluate_audio_video.py - creates a 2x2 matrix comparing audio and video unimodal outputs
17. evaluate_filters.ipynb - ipynb to study the filters learnt in a model
18. evaluate_history.ipynb - evaluates histories from a model to determine what a good early stopping criteria would be
19. evaluate_majority_voting.ipynb - used to evaluate performance with majority voting
20. evaluate_model_performance.ipynb - compared classwise precision, recall and f1-score for all three models (of split 1)
21. Explore_seqs.ipynb - ipynb used to quickly calculate ragawise distribution of dataset
22. extract_intensity-test.py - Extracted voice contour related features from audio (original and SS). Also contains code to automatically convert audio to mono wav format.
23. extract_seqs.py - python script to extract subsequences. This generates a summary file with start and stop times for subsequences.
24. extract_ss_pitch.py - python script to extract pitch contours from every audio file
25. extract_tonic_files - script to extract the tonic of audio files 
26. generate_audio_clips.py - splits the audio clips according to the start time of all subsequences in the dataset
27. generate_hist.ipynb - generates histogram with audio, video, audio-video predictions, used to generate figure in the paper
28. generate_video_data.py - modified version of music_raga_gendata_nithya.py which generates data in the format required by the inception inspired models
29. LOG_AND_LOAD_DATA.py - logs and loads data in wandb
30. log_and_load-video.py - logs video data in wandb
31. LOG_EVALUATE.py - Logs evaluation of the model on wandb
32. logger.py - logging script (by Mithilesh)
33. music_raga_gendata_nithya - Slightly modified Jin's script that splits data into train-test split and generates it in a format for the MS-G3D model. 
34. new_data_extraction_combine_pipeline.py - data extraction for ensemble data (in the Final Both Data folder)
35. new_data_extraction_video_pipeline.py - data extraction for video data (in Final Both Data folder)
36. new-data-extraction-pipeline-audio.py - data extraction for video data (in Final Both Data folder)
37. No_seq_study.ipynb - studies number of sequences from the summary file; unlike Explore_seqs.ipynb which studies from the train and test set
38. normalize-all.py - normalizes pitch contours with predefined max and min values of the contour. This allows uniformity of normalized contour everywhere.
39. objects.py - File with functions related to model training (with wandb logging)
40. plot-final-data.ipynb - plots the audio and video data for a given sample. Used to generate plots in the supplementary material
41. plot-video-data.ipynb - plots data for all sequences in a folder
42. PredictionProb.ipynb - IPython Notebook to visualise the Probabilites of correctly and incorrectly predicted samples
43. replace_pitch_files.py - replaced the original pitch files in the data folder with interpolated pitch files (done)
44. resample_data.py - resample audio and video data to length 600 (for input fusion model)
45. resynth.py - creates resynthesis of pitch contours
46. sample_savgol.ipynb - notebook to test out the savgol filter
47. SP len.ipynb - calculates the length of all breath phrases; used to calculate average breath phrase length among all three singers
48. split_1_baseline.ipynb - basic ipynb to run model used in beginning stages (no modularity implemented, all definitions in the notebook itself)
49. MODEL_TRAINING_DRIVER_SCRIPT.py - script to run experiments with different model configs (defined by json files) on split 1 of data 
50. standardize_pitch_contour.py - script to standardize each pitch contour to have mean 0 and standard deviation as 1
51. summarizeData.ipynb - summarizes the dataset
52. summary_precision_change.py - generate summary with precise start and end times (in multiples of 0.02s). Used for early fusion model.
53. SWEEP.py - script to run a sweep on wandb for hyperparameter tuning
54. table_to_csv.py - generate csv file from a wandb table
55. test_data.ipynb - check the values stored in train and test splits of data and target values
56. test_sweep.ipynb - notebook to run a test sweep on wandb
57. util_functions.py - basic utility functions for running model
58. write_pred_to_vide.py - generate vidieos with predictions overlayed on top
59. write_preds_to_csv.py - write audio, video and audio-video predictions to a csv file
60. DATA_CREATION_DRIVER_SCRIPT.py - driver script to create a dataset.